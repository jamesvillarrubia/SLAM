{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines count is 3437350\n",
      "within line 0\n",
      "Loaded 0 instances across 10000 exercises...\n",
      "Loaded 0 instances across 20000 exercises...\n",
      "within line 100000\n",
      "Loaded 0 instances across 30000 exercises...\n",
      "Loaded 0 instances across 40000 exercises...\n",
      "within line 200000\n",
      "Loaded 0 instances across 50000 exercises...\n",
      "Loaded 0 instances across 60000 exercises...\n",
      "within line 300000\n",
      "Loaded 0 instances across 70000 exercises...\n",
      "Loaded 0 instances across 80000 exercises...\n",
      "within line 400000\n",
      "Loaded 0 instances across 90000 exercises...\n",
      "Loaded 0 instances across 100000 exercises...\n",
      "within line 500000\n",
      "Loaded 0 instances across 110000 exercises...\n",
      "Loaded 0 instances across 120000 exercises...\n",
      "within line 600000\n",
      "Loaded 0 instances across 130000 exercises...\n",
      "Loaded 0 instances across 140000 exercises...\n",
      "within line 700000\n",
      "Loaded 0 instances across 150000 exercises...\n",
      "Loaded 0 instances across 160000 exercises...\n",
      "Loaded 0 instances across 170000 exercises...\n",
      "within line 800000\n",
      "Loaded 0 instances across 180000 exercises...\n",
      "Loaded 0 instances across 190000 exercises...\n",
      "within line 900000\n",
      "Loaded 0 instances across 200000 exercises...\n",
      "Loaded 0 instances across 210000 exercises...\n",
      "within line 1000000\n",
      "Loaded 0 instances across 220000 exercises...\n",
      "Loaded 0 instances across 230000 exercises...\n",
      "within line 1100000\n",
      "Loaded 0 instances across 240000 exercises...\n",
      "Loaded 0 instances across 250000 exercises...\n",
      "within line 1200000\n",
      "Loaded 0 instances across 260000 exercises...\n",
      "Loaded 0 instances across 270000 exercises...\n",
      "within line 1300000\n",
      "Loaded 0 instances across 280000 exercises...\n",
      "Loaded 0 instances across 290000 exercises...\n",
      "within line 1400000\n",
      "Loaded 0 instances across 300000 exercises...\n",
      "Loaded 0 instances across 310000 exercises...\n",
      "Loaded 0 instances across 320000 exercises...\n",
      "within line 1500000\n",
      "Loaded 0 instances across 330000 exercises...\n",
      "Loaded 0 instances across 340000 exercises...\n",
      "within line 1600000\n",
      "Loaded 0 instances across 350000 exercises...\n",
      "Loaded 0 instances across 360000 exercises...\n",
      "within line 1700000\n",
      "Loaded 0 instances across 370000 exercises...\n",
      "Loaded 0 instances across 380000 exercises...\n",
      "within line 1800000\n",
      "Loaded 0 instances across 390000 exercises...\n",
      "Loaded 0 instances across 400000 exercises...\n",
      "within line 1900000\n",
      "Loaded 0 instances across 410000 exercises...\n",
      "Loaded 0 instances across 420000 exercises...\n",
      "within line 2000000\n",
      "Loaded 0 instances across 430000 exercises...\n",
      "Loaded 0 instances across 440000 exercises...\n",
      "within line 2100000\n",
      "Loaded 0 instances across 450000 exercises...\n",
      "Loaded 0 instances across 460000 exercises...\n",
      "within line 2200000\n",
      "Loaded 0 instances across 470000 exercises...\n",
      "Loaded 0 instances across 480000 exercises...\n",
      "within line 2300000\n",
      "Loaded 0 instances across 490000 exercises...\n",
      "Loaded 0 instances across 500000 exercises...\n",
      "Loaded 0 instances across 510000 exercises...\n",
      "within line 2400000\n",
      "Loaded 0 instances across 520000 exercises...\n",
      "Loaded 0 instances across 530000 exercises...\n",
      "within line 2500000\n",
      "Loaded 0 instances across 540000 exercises...\n",
      "Loaded 0 instances across 550000 exercises...\n",
      "within line 2600000\n",
      "Loaded 0 instances across 560000 exercises...\n",
      "Loaded 0 instances across 570000 exercises...\n",
      "within line 2700000\n",
      "Loaded 0 instances across 580000 exercises...\n",
      "Loaded 0 instances across 590000 exercises...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-15008bc29acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mcreate_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/data_es_en/es_en.slam.20171218.train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-15008bc29acf>\u001b[0m in \u001b[0;36mcreate_csv\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mrecords_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# If the line starts with #, then we're beginning a new exercise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'only recognize index or columns for orient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5500\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5501\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5503\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5807\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dict_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5808\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5809\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5810\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5811\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def create_csv(input_path):\n",
    "\n",
    "    training = (\"train\" in input_path)    \n",
    "    columns=['user','countries','days','client','session','format','time','instance_id','token','part_of_speech','dependency_label','dependency_edge_head','correctness']\n",
    "    df=pd.DataFrame(columns=columns)\n",
    "    num_exercises=0\n",
    "    csv_path=input_path+\".csv\"\n",
    "    records=[]\n",
    "    \n",
    "    lines=open(input_path).readlines()\n",
    "    print(\"Total lines count is \"+str(len(lines)))\n",
    "    for count,line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if count%100000==0:\n",
    "            print(\"within line \"+str(count))\n",
    "\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        if len(line) == 0:\n",
    "            num_exercises += 1\n",
    "            if num_exercises % 10000 == 0:\n",
    "                print('Loaded ' + str(len(df.index)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                records_dict=dict()\n",
    "                for ind,record in enumerate(records):\n",
    "                    records_dict[ind]=record\n",
    "                df.from_dict(records_dict,orient='index').to_csv(csv_path)\n",
    "\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "            list_of_exercise_parameters = line[2:].split()\n",
    "            exercise_properties = dict()\n",
    "            for exercise_parameter in list_of_exercise_parameters:\n",
    "                [key, value] = exercise_parameter.split(':')\n",
    "                if key=='user':\n",
    "                    value=str(value)\n",
    "                if key == 'countries':\n",
    "                    value = value.split('|')[0]  # select the very first country that the user specified\n",
    "#                     if (len(value)>1):\n",
    "#                         print(\"This user has more than one country \"+line)\n",
    "                \n",
    "                elif key == 'days':\n",
    "                    value = float(value)\n",
    "                elif key == 'client':\n",
    "                    value = (1 if value==\"web\" else (2 if value==\"ios\" else 3))\n",
    "                elif key=='session':\n",
    "                    value=(1 if value==\"lesson\" else (2 if value==\"practice\" else 3))\n",
    "                elif key=='format':\n",
    "                    value=(1 if value==\"reverse_translate\" else (2 if value==\"reverse_tap\" else 3))\n",
    "                elif key == 'time':\n",
    "                    if value == 'null' or float(value)<=0:\n",
    "                        value = None\n",
    "                    else:\n",
    "                        assert '.' not in value\n",
    "                        value = int(value)\n",
    "                if value!=None:\n",
    "                    exercise_properties[key] = value\n",
    "\n",
    "        # Otherwise we're parsing a new Instance for the current exercise\n",
    "        else:\n",
    "            instance_properties=dict(exercise_properties)\n",
    "            line = line.split()\n",
    "            if training:\n",
    "                assert len(line) == 7\n",
    "            else:\n",
    "                assert len(line) == 6\n",
    "            assert len(line[0]) == 12\n",
    "            \n",
    "#             instance_properties['instance_id']=line[0]\n",
    "            instance_properties['session_id'] = line[0][:8]\n",
    "            instance_properties['exercise_id'] = int(line[0][8:10])\n",
    "            instance_properties['token_id']=int(line[0][10:12])\n",
    "            instance_properties['token'] = line[1]\n",
    "            instance_properties['part_of_speech'] = line[2]\n",
    "            # TODO starts\n",
    "            for l in line[3].split('|'):\n",
    "                [key, value] = l.split('=')\n",
    "                if key == 'Person':\n",
    "                    value = int(value)\n",
    "                instance_properties['morphological_features_'+key]=value\n",
    "                \n",
    "            # TODO ends\n",
    "\n",
    "            instance_properties['dependency_label'] = line[4]\n",
    "            instance_properties['dependency_edge_head'] = int(line[5])\n",
    "            if training:\n",
    "                instance_properties['correctness'] = float(line[6])\n",
    "#             df=df.append(instance_properties,ignore_index=True)\n",
    "            records+=[instance_properties]\n",
    "        \n",
    "#         df.to_csv(csv_path)\n",
    "                \n",
    "                \n",
    "create_csv(\"../data/data_es_en/es_en.slam.20171218.train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
